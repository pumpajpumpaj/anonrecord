<!DOCTYPE html>
<html>

<head>
  <title>Recorder</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    canvas,
    video {
      position: absolute;
      top: 0;
      left: 0;
    }

    #container {
      position: relative;
      width: 640px;
      height: 480px;
    }
  </style>
</head>

<body>
  <label for="cameraSelect">Choose camera:</label>
  <select id="cameraSelect"></select>
  <div>
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
    <a id="downloadLink" style="display:none" download="censored-video.mp4">Download video</a>
  </div>  <div id="container">
    <video id="video" autoplay muted playsinline width="1280" height="720"></video>
    <canvas id="canvas" width="640" height="480"></canvas>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.12.2/dist/ffmpeg.min.js"></script>
  <script>

    function loadOpenCV() {
      return new Promise((resolve, reject) => {
        const script = document.createElement('script');
        script.src = 'https://docs.opencv.org/4.5.5/opencv.js';
        script.async = true;
        script.onload = () => {
          cv['onRuntimeInitialized'] = () => resolve();
        };
        script.onerror = reject;
        document.body.appendChild(script);
      });
    }
    let mediaRecorder = null;
    let recordedChunks = [];
    let micStream = null;
    const SMOOTHING_WINDOW = 55;

    let previousFaces = [];
    const MAX_MISSING_FRAMES = 13;
    function averageBoxes(history) {
      const len = history.length;
      const sum = history.reduce((acc, box) => {
        return [
          acc[0] + box[0],
          acc[1] + box[1],
          acc[2] + box[2],
          acc[3] + box[3],
        ];
      }, [0, 0, 0, 0]);
      return sum.map(x => Math.round(x / len));
    }

    function computeIoU(boxA, boxB) {
      const xA = Math.max(boxA[0], boxB[0]);
      const yA = Math.max(boxA[1], boxB[1]);
      const xB = Math.min(boxA[2], boxB[2]);
      const yB = Math.min(boxA[3], boxB[3]);

      const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
      if (interArea === 0) return 0;

      const boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]);
      const boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]);

      return interArea / (boxAArea + boxBArea - interArea);
    }

    let session = null;
    let labels = [];
    const THRESHOLD = 0.8;
    const IOU_THRESHOLD = 0.5;
    const MODEL_URL = "ultraface.onnx";


    async function setupRecordingWithAudio(canvas) {
      const startBtn = document.getElementById('startBtn');
      const stopBtn = document.getElementById('stopBtn');
      const downloadLink = document.getElementById('downloadLink');


      const canvasStream = canvas.captureStream(25);


      micStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 48000
        }
      });


      const combinedStream = new MediaStream([
        ...canvasStream.getVideoTracks(),
        ...micStream.getAudioTracks()
      ]);


      mediaRecorder = new MediaRecorder(combinedStream, { mimeType: 'video/webm;codecs=vp8,opus' });

      mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) recordedChunks.push(e.data);
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const mp4 =  convertWebMtoMP4(blob);
        recordedChunks = [];

        const url = URL.createObjectURL(mp4);
        downloadLink.href = url;
        downloadLink.style.display = 'inline-block';
        downloadLink.innerText = 'Download video';


        micStream.getTracks().forEach(track => track.stop());
      };

      startBtn.onclick = () => {
        recordedChunks = [];
        mediaRecorder.start();
        startBtn.disabled = true;
        stopBtn.disabled = false;
        downloadLink.style.display = 'none';
      };

      stopBtn.onclick = () => {
        mediaRecorder.stop();
        startBtn.disabled = false;
        stopBtn.disabled = true;
      };
    }

    async function loadLabels() {
      labels = ['background', 'face'];
    }

    function softNMS(boxes, scores, iouThreshold) {
      const picked = [];
      const areas = boxes.map(b => (b[2] - b[0]) * (b[3] - b[1]));
      const order = scores.map((s, i) => [s, i]).sort((a, b) => b[0] - a[0]).map(e => e[1]);

      while (order.length > 0) {
        const i = order.shift();
        picked.push(i);
        for (let j = order.length - 1; j >= 0; j--) {
          const o = order[j];
          const xx1 = Math.max(boxes[i][0], boxes[o][0]);
          const yy1 = Math.max(boxes[i][1], boxes[o][1]);
          const xx2 = Math.min(boxes[i][2], boxes[o][2]);
          const yy2 = Math.min(boxes[i][3], boxes[o][3]);
          const w = Math.max(0, xx2 - xx1);
          const h = Math.max(0, yy2 - yy1);
          const inter = w * h;
          const ovr = inter / (areas[i] + areas[o] - inter);
          if (ovr > iouThreshold) order.splice(j, 1);
        }
      }
      return picked;
    }

    function preprocess(mat) {
      let dst = new cv.Mat();
      cv.cvtColor(mat, dst, cv.COLOR_RGBA2RGB);
      cv.resize(dst, dst, new cv.Size(320, 240));
      let imgData = dst.data;
      let float32 = new Float32Array(1 * 3 * 240 * 320);
      const mean = [127, 127, 127];

      for (let i = 0; i < 240; i++) {
        for (let j = 0; j < 320; j++) {
          for (let c = 0; c < 3; c++) {
            let val = imgData[(i * 320 + j) * 3 + c];
            float32[c * 240 * 320 + i * 320 + j] = (val - mean[c]) / 128.0;
          }
        }
      }

      dst.delete();
      return new ort.Tensor("float32", float32, [1, 3, 240, 320]);
    }

    async function runInference(frameMat, ctx) {
      const inputTensor = preprocess(frameMat);
      const output = await session.run({ [session.inputNames[0]]: inputTensor });
      const confidences = output[session.outputNames[0]].data;
      const boxes = output[session.outputNames[1]].data;

      const confArr = Array.from(confidences);
      const boxArr = Array.from(boxes);
      const numAnchors = confidences.length / labels.length;

      const results = [];
      for (let i = 0; i < numAnchors; i++) {
        const score = confArr[i * labels.length + 1];
        if (score > THRESHOLD) {
          const box = [
            boxArr[i * 4 + 0],
            boxArr[i * 4 + 1],
            boxArr[i * 4 + 2],
            boxArr[i * 4 + 3]
          ];
          results.push({ box, score });
        }
      }

      const picked = softNMS(results.map(r => r.box), results.map(r => r.score), IOU_THRESHOLD);
      const currentFaces = [];

      for (let i of picked) {
        let { box } = results[i];
        let [x1, y1, x2, y2] = box.map((v, idx) => idx % 2 === 0 ? v * frameMat.cols : v * frameMat.rows);
        x1 = Math.max(0, Math.floor(x1));
        y1 = Math.max(0, Math.floor(y1));
        x2 = Math.min(frameMat.cols, Math.floor(x2));
        y2 = Math.min(frameMat.rows, Math.floor(y2));

        currentFaces.push({ x1, y1, x2, y2 });

        let rect = new cv.Rect(x1, y1, x2 - x1, y2 - y1);
        let faceROI = frameMat.roi(rect);
        let mean = cv.mean(faceROI);
        faceROI.delete();

        let center = new cv.Point(x1 + (x2 - x1) / 2, y1 + (y2 - y1) / 2);
        let axes = new cv.Size((x2 - x1) / 2, (y2 - y1) / 2);
        cv.ellipse(frameMat, center, axes, 0, 0, 360, new cv.Scalar(0, 0, 0, 255), cv.FILLED);
      }


      const newTracked = [];

      for (const face of previousFaces) {
        let matched = false;

        for (const curr of currentFaces) {
          const iou = computeIoU(
            [face.history.at(-1)[0], face.history.at(-1)[1], face.history.at(-1)[2], face.history.at(-1)[3]],
            [curr.x1, curr.y1, curr.x2, curr.y2]
          );

          if (iou > 0.1) {
            // Match found, update history
            face.history.push([curr.x1, curr.y1, curr.x2, curr.y2]);
            if (face.history.length > SMOOTHING_WINDOW) {
              face.history.shift(); // Keep only last N
            }
            face.missingFrames = 0;
            face.mean = cv.mean(frameMat.roi(new cv.Rect(curr.x1, curr.y1, curr.x2 - curr.x1, curr.y2 - curr.y1)));
            matched = true;
            break;
          }
        }

        if (!matched) {
          face.missingFrames++;
          if (face.missingFrames <= MAX_MISSING_FRAMES) {
            // Draw smoothed ellipse using averaged history
            const [x1, y1, x2, y2] = averageBoxes(face.history);
            const center = new cv.Point(x1 + (x2 - x1) / 2, y1 + (y2 - y1) / 2);
            const axes = new cv.Size((x2 - x1) / 2, (y2 - y1) / 2);
            const mean = face.mean;
            cv.ellipse(frameMat, center, axes, 0, 0, 360, new cv.Scalar(mean[0], mean[1], mean[2], 255), cv.FILLED);
            newTracked.push(face);
          }
        } else {
          newTracked.push(face); // Keep updated face
        }
      }

      // Add unmatched current faces as new tracked entries
      for (const curr of currentFaces) {
        // Avoid duplicates by checking if already tracked
        const alreadyTracked = newTracked.some(face => {
          const last = face.history.at(-1);
          return computeIoU([last[0], last[1], last[2], last[3]], [curr.x1, curr.y1, curr.x2, curr.y2]) > 0.4;
        });
        if (!alreadyTracked) {
          const rect = new cv.Rect(curr.x1, curr.y1, curr.x2 - curr.x1, curr.y2 - curr.y1);
          const roi = frameMat.roi(rect);
          const mean = cv.mean(roi);
          roi.delete();

          newTracked.push({
            history: [[curr.x1, curr.y1, curr.x2, curr.y2]],
            mean,
            missingFrames: 0
          });
        }
      }

      previousFaces = newTracked;


      cv.imshow(ctx.canvas, frameMat);
    }



    let currentStream = null;

    async function getVideoDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(d => d.kind === 'videoinput');
    }

    async function populateCameraList() {
      const cameraSelect = document.getElementById('cameraSelect');
      const devices = await getVideoDevices();
      cameraSelect.innerHTML = '';
      devices.forEach((device, index) => {
        const option = document.createElement('option');
        option.value = device.deviceId;
        option.text = device.label || `Camera ${index + 1}`;
        cameraSelect.appendChild(option);
      });
      return devices;
    }

    // async function startCameraById(deviceId) {
    //   if (currentStream) {
    //     currentStream.getTracks().forEach(t => t.stop());
    //   }
    // 
    //   const constraints = {
    //     video: {
    //       deviceId: { exact: deviceId },
    //       width: { ideal: 640 },
    //       height: { ideal: 480 },
    //     }
    //   };
    // 
    //   const stream = await navigator.mediaDevices.getUserMedia(constraints);
    //   currentStream = stream;
    // 
    //   const video = document.getElementById('video');
    //   video.srcObject = stream;
    // 
    //   return new Promise(resolve => {
    //     video.onloadedmetadata = () => {
    //       video.play();
    //       resolve();
    //     };
    //   });
    // }
    async function startCameraById(deviceId) {
      if (currentStream) {
        currentStream.getTracks().forEach(t => t.stop());
      }

      const constraints = {
        video: {
          deviceId: { exact: deviceId },
          width: { ideal: 1280 },
          height: { ideal: 720 }
        },

        audio: false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      currentStream = stream;

      const video = document.getElementById('video');
      video.srcObject = stream;
      video.videoWidth
      await new Promise(resolve => {
        video.onloadedmetadata = () => resolve();
      });

      // Set canvas size to match video native resolution:
      const canvas = document.getElementById('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.clientWidth = video.videoWidth;
      canvas.clientHeight = video.videoHeight;

      return;
    }


    async function mainLoop(video, canvas) {
      const ctx = canvas.getContext('2d');
      const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      const cap = new cv.VideoCapture(video);

      async function loop() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        cap.read(src);
        await runInference(src, ctx);
        requestAnimationFrame(loop);
      }

      loop();
    }


    async function initCameraSelection() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        stream.getTracks().forEach(t => t.stop()); // immediately stop it, just need permission
        const devices = await navigator.mediaDevices.enumerateDevices();
        const videoDevices = devices.filter(d => d.kind === 'videoinput');
        const cameraSelect = document.getElementById('cameraSelect');
        cameraSelect.innerHTML = '';

        videoDevices.forEach((device, idx) => {
          const option = document.createElement('option');
          option.value = device.deviceId;
          option.text = device.label || `Camera ${idx + 1}`;
          cameraSelect.appendChild(option);
        });

        if (videoDevices.length > 0) {
          cameraSelect.value = videoDevices[0].deviceId;
          await startCameraById(cameraSelect.value);
        }

        // 3. Listen for dropdown changes
        cameraSelect.addEventListener('change', async e => {
          await startCameraById(e.target.value);
        });

      } catch (err) {
        console.error('Error accessing camera:', err);
        alert('Please grant camera permission to select cameras.');
      }
    }


    async function init() {
      await loadOpenCV();
      await loadLabels();
      session = await ort.InferenceSession.create(MODEL_URL);
      await initCameraSelection();
      const canvas = document.getElementById('canvas');
      const video = document.getElementById('video');
      const cameraSelect = document.getElementById('cameraSelect');

      const devices = await populateCameraList();

      if (devices.length === 0) {
        alert("No video input devices found.");
        return;
      }

      await startCameraById(devices[0].deviceId);
      await mainLoop(video, canvas);
      await setupRecordingWithAudio(document.getElementById('canvas'));

      cameraSelect.addEventListener('change', async (e) => {
        await startCameraById(e.target.value);
      });
    }

    async function convertWebMtoMP4(webmBlob) {
      const { createFFmpeg, fetchFile } = FFmpeg;
      const ffmpeg = createFFmpeg({ log: true });

      if (!ffmpeg.isLoaded()) {
        await ffmpeg.load();
      }

      // Write the WebM file to the virtual FS
      ffmpeg.FS('writeFile', 'input.webm', await fetchFile(webmBlob));

      // Convert to MP4
      await ffmpeg.run('-i', 'input.webm', '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23', 'output.mp4');

      // Read the MP4 result
      const mp4Data = ffmpeg.FS('readFile', 'output.mp4');

      // Convert Uint8Array to Blob
      const mp4Blob = new Blob([mp4Data.buffer], { type: 'video/mp4' });

      return mp4Blob;
    }

    init();
  </script>
</body>

</html>
